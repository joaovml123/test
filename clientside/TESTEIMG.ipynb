{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face 1: Bounding box [(startX: 859, startY: 963), (endX: 1547, endY: 2075)], Confidence: 0.9997692704200745\n",
      "Server response: {'name': 'jack'}\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def detect_faces_with_dnn_and_send_to_server(image_path, server_url):\n",
    "    # Load pre-trained model from OpenCV DNN (Caffe model for face detection)\n",
    "    net = cv2.dnn.readNetFromCaffe(\"deploy.prototxt\", \"res10_300x300_ssd_iter_140000.caffemodel\")\n",
    "\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    # Preprocess the image: resize, normalize\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "\n",
    "    face_locations = []\n",
    "\n",
    "    # Loop over the detections\n",
    "    for i in range(0, detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "\n",
    "        # Filter out weak detections (confidence threshold can be adjusted)\n",
    "        if confidence > 0.5:\n",
    "            # Get the bounding box for the detected face\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "            # Append to face locations list\n",
    "            face_locations.append((startY, endX, endY, startX))\n",
    "\n",
    "            # Print the bounding box and confidence\n",
    "            print(f\"Face {i+1}: Bounding box [(startX: {startX}, startY: {startY}), (endX: {endX}, endY: {endY})], Confidence: {confidence}\")\n",
    "\n",
    "            # Draw the bounding box around the face\n",
    "            cv2.rectangle(image, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "\n",
    "    # Check if any faces were detected\n",
    "    if len(face_locations) > 0:\n",
    "        # Get the face encodings for the detected faces using face_recognition\n",
    "        face_encodings = face_recognition.face_encodings(image, face_locations)\n",
    "\n",
    "        # Prepare the data to send to the server\n",
    "        data_to_send = {\n",
    "            'encodings': [encoding.tolist() for encoding in face_encodings]  # Convert numpy arrays to lists\n",
    "        }\n",
    "\n",
    "        # Send the face encodings to the server for recognition\n",
    "        response = requests.post(server_url, json=data_to_send)\n",
    "\n",
    "        # Print the server's response\n",
    "        print(\"Server response:\", response.json())\n",
    "\n",
    "        # Exit the function after the server response to stop further execution\n",
    "        return\n",
    "    else:\n",
    "        print(\"No faces detected.\")\n",
    "\n",
    "    # If the function has not exited by this point, show the image with detected faces\n",
    "    cv2.imshow(\"Detected Faces\", image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Test the function\n",
    "image_path = 'jack2.jpeg'\n",
    "server_url = 'http://127.0.0.1:5000/recognize'\n",
    "detect_faces_with_dnn_and_send_to_server(image_path, server_url)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
